{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df65f99a-903f-4e2d-8b48-16147d575163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载测试数据...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './cifar-10-batches-py/test_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 330\u001b[0m\n\u001b[1;32m    327\u001b[0m output_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model_test_results\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 结果输出目录\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# 测试模型\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_weights_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# 可视化模型权重\u001b[39;00m\n\u001b[1;32m    333\u001b[0m visualize_model_weights(model_weights_path, output_directory)\n",
      "Cell \u001b[0;32mIn[1], line 126\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model_path, test_data_path, output_dir)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m加载测试数据...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m tester \u001b[38;5;241m=\u001b[39m ModelTester()\n\u001b[0;32m--> 126\u001b[0m test_data, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_cifar10_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# 数据预处理\u001b[39;00m\n\u001b[1;32m    129\u001b[0m test_data, _, _ \u001b[38;5;241m=\u001b[39m tester\u001b[38;5;241m.\u001b[39mpreprocess_data(test_data)\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mModelTester.load_cifar10_batch\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cifar10_batch\u001b[39m(file):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"加载CIFAR-10数据集批次\"\"\"\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fo:\n\u001b[1;32m     14\u001b[0m         batch \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fo, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     data \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cifar-10-batches-py/test_batch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# 模型测试功能类\n",
    "class ModelTester:\n",
    "    \"\"\"用于加载和测试神经网络模型的工具类\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_cifar10_batch(file):\n",
    "        \"\"\"加载CIFAR-10数据集批次\"\"\"\n",
    "        with open(file, 'rb') as fo:\n",
    "            batch = pickle.load(fo, encoding='bytes')\n",
    "        data = batch[b'data']\n",
    "        labels = batch[b'labels']\n",
    "        return data, labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_data(data, mean=None, std=None):\n",
    "        \"\"\"数据标准化处理\"\"\"\n",
    "        data = data.astype(np.float32) / 255.0\n",
    "\n",
    "        if mean is None:\n",
    "            mean = np.mean(data, axis=0)\n",
    "        if std is None:\n",
    "            std = np.std(data, axis=0)\n",
    "\n",
    "        std[std == 0] = 1.0\n",
    "        \n",
    "        normalized_data = (data - mean) / std\n",
    "        return normalized_data, mean, std\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_one_hot(labels, num_classes=10):\n",
    "        \"\"\"标签转为one-hot编码\"\"\"\n",
    "        one_hot = np.zeros((labels.shape[0], num_classes))\n",
    "        one_hot[np.arange(labels.shape[0]), labels] = 1\n",
    "        return one_hot\n",
    "\n",
    "# 激活函数类\n",
    "class Activation:\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "# 三层神经网络模型\n",
    "class ThreeLayerNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size, activation='relu'):\n",
    "        \"\"\"初始化神经网络\"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # 设置激活函数\n",
    "        if activation == 'relu':\n",
    "            self.activation = Activation.relu\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = Activation.sigmoid\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = Activation.tanh\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的激活函数: {activation}\")\n",
    "        \n",
    "        # 初始化权重和偏置\n",
    "        self.W1 = np.zeros((input_size, hidden_size))\n",
    "        self.b1 = np.zeros(hidden_size)\n",
    "        self.W2 = np.zeros((hidden_size, output_size))\n",
    "        self.b2 = np.zeros(output_size)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        # 第一层: 输入 -> 隐藏层\n",
    "        Z1 = np.dot(X, self.W1) + self.b1\n",
    "        A1 = self.activation(Z1)\n",
    "        \n",
    "        # 第二层: 隐藏层 -> 输出\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        A2 = Activation.softmax(Z2)\n",
    "        \n",
    "        return A2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"预测类别标签\"\"\"\n",
    "        probabilities = self.forward(X)\n",
    "        return np.argmax(probabilities, axis=1)\n",
    "    \n",
    "    def load_weights(self, file_path):\n",
    "        \"\"\"从文件加载模型权重\"\"\"\n",
    "        weights = np.load(file_path)\n",
    "        self.W1 = weights['W1']\n",
    "        self.b1 = weights['b1']\n",
    "        self.W2 = weights['W2']\n",
    "        self.b2 = weights['b2']\n",
    "        print(f\"已加载权重。W1形状: {self.W1.shape}, W2形状: {self.W2.shape}\")\n",
    "\n",
    "def test_model(model_path, test_data_path, output_dir='./test_results'):\n",
    "    \"\"\"\n",
    "    测试神经网络模型性能\n",
    "    \n",
    "    参数:\n",
    "    model_path: 模型权重文件路径\n",
    "    test_data_path: 测试数据文件路径\n",
    "    output_dir: 输出结果的目录\n",
    "    \"\"\"\n",
    "    # 创建输出目录（如果不存在）\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 加载测试数据\n",
    "    print(\"加载测试数据...\")\n",
    "    tester = ModelTester()\n",
    "    test_data, test_labels = tester.load_cifar10_batch(test_data_path)\n",
    "    \n",
    "    # 数据预处理\n",
    "    test_data, _, _ = tester.preprocess_data(test_data)\n",
    "    print(f\"测试数据形状: {test_data.shape}\")\n",
    "    \n",
    "    # 创建模型\n",
    "    input_size = test_data.shape[1]\n",
    "    hidden_size = 256  # 与训练时使用的隐藏层大小相同\n",
    "    output_size = 10   # CIFAR-10有10个类别\n",
    "    \n",
    "    model = ThreeLayerNN(input_size, hidden_size, output_size, activation='relu')\n",
    "    \n",
    "    # 加载模型权重\n",
    "    print(f\"从 {model_path} 加载模型权重...\")\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    # 测试模型\n",
    "    print(\"评估模型性能...\")\n",
    "    predictions = model.predict(test_data)\n",
    "    accuracy = np.mean(predictions == test_labels)\n",
    "    print(f\"测试准确率: {accuracy:.4f}\")\n",
    "    \n",
    "    # 可视化一些预测结果\n",
    "    num_samples_to_show = min(10, test_data.shape[0])\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    for i in range(num_samples_to_show):\n",
    "        # 获取原始图像数据\n",
    "        img = test_data[i].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        \n",
    "        # 标准化为可视化\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        # 获取预测结果和真实标签\n",
    "        pred = predictions[i]\n",
    "        true_label = test_labels[i]\n",
    "        \n",
    "        # 显示图像\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"预测: {pred}, 真实: {true_label}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'prediction_samples.png'))\n",
    "    \n",
    "    # 创建混淆矩阵\n",
    "    conf_matrix = np.zeros((output_size, output_size), dtype=int)\n",
    "    for i in range(len(test_labels)):\n",
    "        conf_matrix[test_labels[i], predictions[i]] += 1\n",
    "    \n",
    "    # 可视化混淆矩阵\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('混淆矩阵')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.xticks(np.arange(output_size), np.arange(output_size))\n",
    "    plt.yticks(np.arange(output_size), np.arange(output_size))\n",
    "    plt.xlabel('预测标签')\n",
    "    plt.ylabel('真实标签')\n",
    "    \n",
    "    # 在混淆矩阵中添加数值\n",
    "    thresh = conf_matrix.max() / 2\n",
    "    for i in range(output_size):\n",
    "        for j in range(output_size):\n",
    "            plt.text(j, i, str(conf_matrix[i, j]),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
    "    \n",
    "    # 计算每个类别的准确率\n",
    "    class_accuracies = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    \n",
    "    # 可视化每个类别的准确率\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(np.arange(output_size), class_accuracies)\n",
    "    plt.xticks(np.arange(output_size), np.arange(output_size))\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.xlabel('类别')\n",
    "    plt.ylabel('准确率')\n",
    "    plt.title('每个类别的准确率')\n",
    "    \n",
    "    # 在柱状图上添加具体数值\n",
    "    for i, acc in enumerate(class_accuracies):\n",
    "        plt.text(i, acc + 0.02, f'{acc:.2f}', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'class_accuracies.png'))\n",
    "    \n",
    "    print(\"测试完成！结果已保存到\", output_dir)\n",
    "    return accuracy\n",
    "\n",
    "def visualize_model_weights(model_path, output_dir='./test_results'):\n",
    "    \"\"\"\n",
    "    可视化模型权重\n",
    "    \n",
    "    参数:\n",
    "    model_path: 模型权重文件路径\n",
    "    output_dir: 输出结果的目录\n",
    "    \"\"\"\n",
    "    # 创建输出目录（如果不存在）\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 创建模型并加载权重\n",
    "    input_size = 3072  # 32x32x3\n",
    "    hidden_size = 256\n",
    "    output_size = 10\n",
    "    \n",
    "    model = ThreeLayerNN(input_size, hidden_size, output_size)\n",
    "    model.load_weights(model_path)\n",
    "    \n",
    "    # 可视化第一层权重\n",
    "    W1 = model.W1  # 形状: [3072, hidden_size]\n",
    "    \n",
    "    # 对于CIFAR-10，输入为32x32x3（展平为3072）\n",
    "    input_shape = (32, 32, 3)\n",
    "    n_features = W1.shape[1]  # 隐藏神经元数量\n",
    "    \n",
    "    # 为第一层创建图形\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.suptitle(\"第一层权重\", fontsize=16, y=0.98)\n",
    "    \n",
    "    # 确定可视化的网格大小\n",
    "    grid_size = int(np.ceil(np.sqrt(n_features)))\n",
    "    \n",
    "    # 对权重进行归一化以便更好地可视化\n",
    "    W1_min, W1_max = W1.min(), W1.max()\n",
    "    \n",
    "    # 将每个隐藏神经元的权重绘制为图像\n",
    "    for i in range(min(n_features, grid_size**2)):\n",
    "        ax = plt.subplot(grid_size, grid_size, i + 1)\n",
    "        \n",
    "        # 将权重重塑为输入图像的维度\n",
    "        weight_img = W1[:, i].reshape(input_shape)\n",
    "        \n",
    "        # 归一化到[0, 1]以便可视化\n",
    "        weight_img = (weight_img - W1_min) / (W1_max - W1_min)\n",
    "        \n",
    "        # 显示权重图像\n",
    "        plt.imshow(weight_img)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 在每个子图周围添加边框\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_color('black')\n",
    "            spine.set_linewidth(0.5)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.savefig(os.path.join(output_dir, 'weights_layer1.png'))\n",
    "    \n",
    "    # 可视化第二层权重\n",
    "    W2 = model.W2  # 形状: [hidden_size, output_size]\n",
    "    \n",
    "    # 为第二层创建图形\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.suptitle(\"第二层权重\", fontsize=16, y=0.98)\n",
    "    \n",
    "    # 对权重进行归一化以便更好地可视化\n",
    "    W2_min, W2_max = W2.min(), W2.max()\n",
    "    \n",
    "    # 将每个输出神经元的权重绘制为图像\n",
    "    for i in range(output_size):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        \n",
    "        # 获取此输出神经元的权重\n",
    "        weight_data = W2[:, i]\n",
    "        \n",
    "        # 将权重重塑为矩形图像以便显示\n",
    "        side_length = int(np.ceil(np.sqrt(len(weight_data))))\n",
    "        \n",
    "        # 填充权重以形成方形网格\n",
    "        padding = side_length**2 - len(weight_data)\n",
    "        if padding > 0:\n",
    "            weight_data = np.hstack([weight_data, np.zeros(padding)])\n",
    "        \n",
    "        # 重塑为方形网格\n",
    "        weight_img = weight_data.reshape(side_length, side_length)\n",
    "        \n",
    "        # 归一化到[0, 1]以便可视化\n",
    "        weight_img = (weight_img - W2_min) / (W2_max - W2_min)\n",
    "        \n",
    "        # 显示权重图像\n",
    "        plt.imshow(weight_img, cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"类别 {i}\", fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'weights_layer2.png'))\n",
    "    \n",
    "    print(\"权重可视化完成！结果已保存到\", output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置参数\n",
    "    model_weights_path = \"./best_model.npz\"  # 权重文件路径\n",
    "    test_data_path = \"./cifar-10-batches-py/test_batch\"  # 测试数据路径\n",
    "    output_directory = \"./model_test_results\"  # 结果输出目录\n",
    "    \n",
    "    # 测试模型\n",
    "    test_accuracy = test_model(model_weights_path, test_data_path, output_directory)\n",
    "    \n",
    "    # 可视化模型权重\n",
    "    visualize_model_weights(model_weights_path, output_directory)\n",
    "    \n",
    "    print(f\"测试已完成。最终测试准确率: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac367e1-8120-4454-a402-838dea906fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
